{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54450805-7cab-417e-bee2-85795cb167b1",
   "metadata": {},
   "source": [
    "## 00. Pytorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fc0776-1149-40d7-b91d-3c067526979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae1eb4d-89e6-4157-bac8-9e673c7f245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c111abb9-a7b0-4b11-af90-b2d5c4cd7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ee588-8d46-4740-a559-f6c98142a517",
   "metadata": {},
   "source": [
    "### Introduction to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0ee7ee-3070-4d68-b216-c01676e4d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch tensors are created using \"torch.tensor()\"\n",
    "scalar_num = torch.tensor(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914b2514-fac5-4880-b779-c09dbd8056f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40620399-2a95-49a3-bc30-a06abf9ec8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_num.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d11e4dd2-e087-4e86-ab53-17d10bd28b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd1f6acf-29ce-4ecb-a96d-7b87efa24fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_num.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd062af4-cd61-4593-b82e-7130d343a282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_num.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c64e9d83-28d3-47d4-a72a-724293d58656",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_num = torch.tensor([5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "848dfbbe-5113-455b-9eba-f1c972a5f585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_num.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a95809f-cdf7-461d-a709-6655088b2791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73ae70d6-ff28-4309-b72b-ea97ce40ec75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f54cd896-29da-4361-8064-991f5e0b8da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_num.ndim\n",
    "# The vector ndim can be checked by the number of brackets before starting of the number \n",
    "# Also as the scalar has 0 dim, vector can be understood as an item having 1 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b94c2fb4-6ee9-426f-9325-b37a5ff98c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape is 2 as the vector has both magnitude and direction\n",
    "# while a scalar does not have any shape, it just has a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bf24a99-70e5-49b0-9ece-e8b046974729",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1833876-150b-4e82-8f8f-9d4bc365c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX = torch.tensor([[2, 3],\n",
    "                       [4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "320d98d9-3950-4808-a7c2-f4e0fd69b431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0740ba70-9b10-45dd-82f3-3c2643c33623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df317ec7-5ee3-413e-bebb-4b87c27e83d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4849d2d4-3dbd-4712-bac4-2d582ddd1305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6673e8d-ab8a-48f7-8b5b-009926012e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4918643-02a4-4e88-add7-602c09fc171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80601377-3ae1-4639-a8cd-50ebba37eccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff961663-662e-4873-9368-d3a5bab4d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d791021-2b41-4d46-818d-5433807eb97a",
   "metadata": {},
   "source": [
    "## Dimension(dim)\n",
    "##### index -    0 1 2\n",
    "##### dimesnion- 1 3 3\n",
    "\n",
    "torch.Size([1, 3, 3])\n",
    "\n",
    "That means there's 1 dimension of 3 by 3 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29d96a5f-03e3-49a8-873d-f042c3a49b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0] # 0th dimension\n",
    "# the far left [ is the 0th dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c40044-a719-4537-8df0-b14cd0f77d2a",
   "metadata": {},
   "source": [
    "#### the second bracket matches with the second 3, which says there are 3 rows of data and the third 3 matches with the number of columns in the matrix\n",
    "refer -  https://www.learnpytorch.io/00_pytorch_fundamentals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "352f672b-e6cf-456f-9d87-b8d3b0544dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR_1 = torch.tensor([[[[1,2,3,4],\n",
    "                          [5,6,7,4],\n",
    "                          [6,6,6,6]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffebb625-2aa2-4651-afa1-27faa7584e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3980cb-81c1-4ac3-b964-9f80dc450a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR_2 = torch.tensor([[[[1,2,3,4],\n",
    "                          [5,6,7,4],\n",
    "                          [6,6,6,6]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2eefd6c0-d4d0-429d-95ec-d4a19506a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Tensor\n",
    "random_tensor = torch.rand(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5231e1bc-1782-413c-923e-f128f3a62184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7482, 0.0992, 0.8893, 0.2259, 0.7204],\n",
       "        [0.2942, 0.2181, 0.3505, 0.3422, 0.5413],\n",
       "        [0.2257, 0.1055, 0.5995, 0.8466, 0.0772],\n",
       "        [0.4861, 0.3263, 0.6476, 0.6332, 0.1553]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1834240b-d9c1-46ba-b405-83f421946a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b10d12d9-0fbb-4af5-8268-1f656ff3ad0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe787225-9e68-4d24-8cc6-affcd856fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a 2 dim random_tensor\n",
    "random_tensor_1 = torch.rand(2,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "327d9c40-6a6e-4108-9640-406d27dc80f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4370, 0.4889],\n",
       "         [0.2748, 0.7986],\n",
       "         [0.3882, 0.5140]],\n",
       "\n",
       "        [[0.9329, 0.1334],\n",
       "         [0.7268, 0.5026],\n",
       "         [0.4955, 0.3233]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56c159f2-ec56-4a31-b0dd-c68a7bdbf864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1,4,5\n",
    "random_tensor_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a23c0cf9-5b99-4dc2-bcf9-f893419530f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6751, 0.6193, 0.4684, 0.1430],\n",
       "         [0.1036, 0.0680, 0.7630, 0.5953],\n",
       "         [0.0889, 0.7451, 0.3008, 0.0432]],\n",
       "\n",
       "        [[0.1044, 0.0210, 0.8685, 0.1370],\n",
       "         [0.5907, 0.7341, 0.6880, 0.0499],\n",
       "         [0.5356, 0.8125, 0.0539, 0.2807]],\n",
       "\n",
       "        [[0.3890, 0.4110, 0.0784, 0.7332],\n",
       "         [0.9943, 0.8386, 0.7625, 0.6436],\n",
       "         [0.5044, 0.7970, 0.9863, 0.7522]],\n",
       "\n",
       "        [[0.2998, 0.0788, 0.4364, 0.4792],\n",
       "         [0.7997, 0.5898, 0.4837, 0.0275],\n",
       "         [0.7030, 0.8884, 0.3972, 0.7442]],\n",
       "\n",
       "        [[0.0086, 0.5486, 0.1588, 0.7542],\n",
       "         [0.4821, 0.8188, 0.8286, 0.4951],\n",
       "         [0.2511, 0.7919, 0.4585, 0.5608]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size = (5,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "228cab99-ca1a-4924-bf04-1b04dc1931fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6dfe212d-60d5-4e65-a99d-01a3780b9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the flexibility of random matrix generation\n",
    "# general image matrix size\n",
    "random_image_size_tensor = torch.rand(size = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14ab4199-16b4-47e3-b96d-bf9197841e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6640, 0.5943, 0.6673],\n",
       "         [0.0258, 0.6458, 0.8062],\n",
       "         [0.5330, 0.9888, 0.8794],\n",
       "         ...,\n",
       "         [0.7965, 0.7765, 0.4101],\n",
       "         [0.6524, 0.4381, 0.0200],\n",
       "         [0.7712, 0.5214, 0.9587]],\n",
       "\n",
       "        [[0.6875, 0.9770, 0.2030],\n",
       "         [0.6008, 0.4195, 0.9765],\n",
       "         [0.9797, 0.6611, 0.1458],\n",
       "         ...,\n",
       "         [0.2912, 0.0059, 0.2464],\n",
       "         [0.6768, 0.1134, 0.7998],\n",
       "         [0.3744, 0.6250, 0.5523]],\n",
       "\n",
       "        [[0.0806, 0.7456, 0.0409],\n",
       "         [0.3013, 0.2061, 0.5254],\n",
       "         [0.5653, 0.6477, 0.1467],\n",
       "         ...,\n",
       "         [0.1241, 0.6488, 0.5631],\n",
       "         [0.8516, 0.6322, 0.9765],\n",
       "         [0.2719, 0.0725, 0.7077]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6154, 0.9830, 0.4565],\n",
       "         [0.9764, 0.0427, 0.6397],\n",
       "         [0.3514, 0.4244, 0.8441],\n",
       "         ...,\n",
       "         [0.9699, 0.5258, 0.5499],\n",
       "         [0.5486, 0.5823, 0.1434],\n",
       "         [0.3771, 0.7598, 0.6294]],\n",
       "\n",
       "        [[0.1982, 0.5442, 0.4699],\n",
       "         [0.9535, 0.7851, 0.3417],\n",
       "         [0.4748, 0.4187, 0.6181],\n",
       "         ...,\n",
       "         [0.0598, 0.6441, 0.3307],\n",
       "         [0.2898, 0.7065, 0.0516],\n",
       "         [0.7949, 0.2340, 0.2506]],\n",
       "\n",
       "        [[0.4822, 0.5067, 0.5396],\n",
       "         [0.4622, 0.1618, 0.4567],\n",
       "         [0.6454, 0.4853, 0.3350],\n",
       "         ...,\n",
       "         [0.2041, 0.8742, 0.3468],\n",
       "         [0.7361, 0.0070, 0.6021],\n",
       "         [0.9270, 0.8008, 0.7572]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea98cd-22e1-4820-b62e-81ca6ba3886a",
   "metadata": {},
   "source": [
    "### Zeros and Ones Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4cd7f8e1-c651-43db-bafa-74a5e9ccaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a tensor with all zeros\n",
    "zeros_tensor = torch.zeros(size = (4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e35d4635-8101-4984-be70-ca36c795e9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor, zeros_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c749139-2269-49a4-84db-4b55ccfd1e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(size = (5,2,5))\n",
    "ones_tensor, ones_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049093aa-dbb1-4667-8069-99108533d057",
   "metadata": {},
   "source": [
    "#### Creating a Range in Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15bb8298-a1cd-46c7-b293-0ee69abfcbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.arange(start, end, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d46d8610-43d4-44c0-a313-aa5bc80291c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  9, 17, 25, 33, 41, 49, 57, 65, 73, 81, 89])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_tensor = torch.arange(1,92,8)\n",
    "zero_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b81d128-50b4-4444-856d-c3c7cab0b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copying the shape of the input tensor with zeros or ones\n",
    "zeros_copy_tensor = torch.zeros_like(zero_to_tensor)\n",
    "zeros_copy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "43f18bea-f056-488a-a7e5-1a134f255040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_like_tensor = torch.ones_like(zeros_tensor)\n",
    "ones_like_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b6c5798f-aa2a-4af8-b250-1a0d0d25563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default datatype for tensors is float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5bd6b69b-1440-4556-b317-7209463e80a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 8.]), torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Default datatype for tensors is float32\n",
    "default_tensor = torch.tensor([3.0,6.0,8.0],\n",
    "                              dtype = None,\n",
    "                              device = None,\n",
    "                              requires_grad = False)\n",
    "# dtype = None, when given like this, it defaults to torch.float32 which is the default dtype for torch tensor\n",
    "#device = None, if device = torch.cude in this case we are using nvidia's gpu for operations,\n",
    "# if not it defaults to default device\n",
    "# requires_grad = False, if it is True, the operations performed on the tensor are recorded\n",
    "# I think this is used during backpropogation\n",
    "\n",
    "default_tensor, default_tensor.shape, default_tensor.dtype, default_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "940b4a3d-b3c3-461e-8e2c-201224232421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 8.], dtype=torch.float16), torch.float16)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor with float 16 dtype\n",
    "float_16_tensor = torch.tensor([3.0,6.0,8.0],\n",
    "                               dtype = torch.float16,\n",
    "                               device = None,\n",
    "                               requires_grad = False)\n",
    "float_16_tensor, float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f8499eee-f70f-442c-8000-c97d36c4741b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'float8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m float_8_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m4.0\u001b[39m,\u001b[38;5;241m2.0\u001b[39m,\u001b[38;5;241m6.9\u001b[39m],\n\u001b[0;32m----> 2\u001b[0m                               dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat8,\n\u001b[1;32m      3\u001b[0m                               device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                               requires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m float_8_tensor, float_8_tensor\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/__init__.py:1938\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1935\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m-> 1938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'float8'"
     ]
    }
   ],
   "source": [
    "float_8_tensor = torch.tensor([4.0,2.0,6.9],\n",
    "                              dtype = torch.float8,\n",
    "                              device = None,\n",
    "                              requires_grad = False)\n",
    "float_8_tensor, float_8_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "79947fc5-2208-4566-8dbf-ae10c78fec53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 9., 36., 64.]), torch.float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_tensor_1 = float_16_tensor * default_tensor\n",
    "mul_tensor_1, mul_tensor_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b4e94dfd-6702-42fd-bee5-95ed675c7f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 5, 6], dtype=torch.int32), torch.int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([4,5,6],\n",
    "                             dtype = torch.int32)\n",
    "int_32_tensor, int_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7c2594e7-d586-4fda-aca6-74b441049d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 30., 48.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1768aaf5-5fc6-4a18-b85d-21a625844d4d",
   "metadata": {},
   "source": [
    "## Getting information from tensors\n",
    "1. Tensors not right datatype - to get the datatype from tensors -> torch.dtype\n",
    "2. Tensors not right shape - to get the shape from tensors -> torch.shape\n",
    "3. Tensors not on right device - to get the device it is stored on -> torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af50eea5-d0ef-4c57-8d4e-ca71d38c6fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4314, 0.0829, 0.9730, 0.9862, 0.9619, 0.5421],\n",
       "        [0.6227, 0.4629, 0.1393, 0.6280, 0.3360, 0.1651],\n",
       "        [0.1216, 0.6507, 0.0762, 0.4053, 0.7994, 0.3649],\n",
       "        [0.5707, 0.2492, 0.5174, 0.4544, 0.7533, 0.2361]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_rand_tensor = torch.rand(4,6)\n",
    "some_rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85ed65bd-9ea0-4939-aaca-ee83a07a5d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the tensor is - torch.Size([4, 6])\n",
      "The datatype of the tensors is - torch.float32\n",
      "The device of the tensors is - cpu\n"
     ]
    }
   ],
   "source": [
    "# Fetching details from the tensor\n",
    "print(f\"The shape of the tensor is - {some_rand_tensor.shape}\")\n",
    "print(f\"The datatype of the tensors is - {some_rand_tensor.dtype}\")\n",
    "print(f\"The device of the tensors is - {some_rand_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df307d0-4b90-465b-9a88-fbc08c98072b",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "1. Addition\n",
    "2. Multiplication (Element-Wise)\n",
    "3. Substraction\n",
    "4. Division\n",
    "5. Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6d9d8cd-e825-43bf-aa8f-eea8be7f62aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 14, 15])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample tensor\n",
    "sample_tensor = torch.tensor([3,4,5])\n",
    "sample_tensor+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e70cf695-4c87-48f6-847c-747880303b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([103, 104, 105])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "sample_tensor + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0e6cd037-a0a4-4465-b74b-2ed6f508c9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([300, 400, 500])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "sample_tensor *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "696e8e81-8877-4e8b-b132-03147ec9fb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0285, 0.4367, 0.8307, 0.2851],\n",
       "        [0.8542, 0.6414, 0.9404, 0.2221],\n",
       "        [0.5263, 0.3346, 0.0341, 0.6752]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Matrix multiplication\n",
    "mat_1 = torch.rand(size = (3,4))\n",
    "mat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a20a927-4525-46b9-a0b8-0701b02f85ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0890, 0.8522, 0.7749, 0.0494],\n",
       "        [0.5547, 0.5735, 0.5228, 0.6593],\n",
       "        [0.8513, 0.0652, 0.4090, 0.8431],\n",
       "        [0.3780, 0.4819, 0.0278, 0.1426]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_2 = torch.rand(size = (4,4))\n",
    "mat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d8552172-939b-4df3-8db1-3abcaefecd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0597, 0.4662, 0.5980, 1.0303],\n",
       "        [1.3163, 1.2642, 1.3880, 1.2896],\n",
       "        [0.5167, 0.9679, 0.6154, 0.3716]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(mat_1, mat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "41dbd380-c94c-44dd-938c-560032c1aaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0597, 0.4662, 0.5980, 1.0303],\n",
       "        [1.3163, 1.2642, 1.3880, 1.2896],\n",
       "        [0.5167, 0.9679, 0.6154, 0.3716]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_1 @ mat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ee5144b2-d816-4585-9be8-22501e01f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2701, 0.3610, 0.4778, 0.9843],\n",
       "         [0.1624, 0.4312, 0.2696, 0.9493],\n",
       "         [0.0557, 0.0845, 0.4933, 0.6158]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_3 = torch.rand(size = (3,4))\n",
    "mat_3, mat_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cf57e7a7-18bd-4cd3-81bc-ffdfa910cf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4646, 0.9350, 0.9207, 0.7288],\n",
       "         [0.6069, 0.2801, 0.0501, 0.2848],\n",
       "         [0.5683, 0.4529, 0.5319, 0.6600]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_4 = torch.rand(size = (3,4))\n",
    "mat_4, mat_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f8a103ce-ba83-43b8-89a2-c248ba0cfa26",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(mat_3, mat_4)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)"
     ]
    }
   ],
   "source": [
    "torch.mm(mat_3, mat_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "65f9a901-7b58-417f-a7e2-7c424a74f96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch Transpose to transpose one matrix and perform matrix multiplication\n",
    "mat_4.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a278122d-4624-4763-8b08-8fc886774cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4646, 0.6069, 0.5683],\n",
       "         [0.9350, 0.2801, 0.4529],\n",
       "         [0.9207, 0.0501, 0.5319],\n",
       "         [0.7288, 0.2848, 0.6600]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_4_transpose = mat_4.T\n",
    "mat_4_transpose, mat_4_transpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c238d09b-1f38-433e-8b8d-e6e016c8ed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1613f459-664e-4bf8-8037-315b1d80c4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.6202, 0.5692, 1.2208],\n",
       "         [1.4186, 0.5032, 1.0576],\n",
       "         [1.0078, 0.2575, 0.7388]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(mat_3, mat_4_transpose), torch.mm(mat_3, mat_4_transpose).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0abe02-ab79-47c6-9e3c-153524ea39c4",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "993ffc69-8468-41a5-869b-dcef78067afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1,50,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "06403b47-dbb3-4630-bdfb-7e6e073e2dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0859593b-a6f6-4283-9bff-cd11375bbb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(41))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0ab04e07-86f5-4b94-bfd3-1c32f1b96e3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmean(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "torch.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "92b88372-fa74-4baa-b175-dd850f0660b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21., dtype=torch.float16)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0e0cd1c9-1704-469a-9f55-e5a2eafb6d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ce4c2-926a-45d8-9a25-2654f545278b",
   "metadata": {},
   "source": [
    "### Finding the positional Min and Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3af6778a-beb1-4154-a773-0931cb72ce22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4), tensor(0))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmax(), x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6a04c1eb-7e86-44ac-bcc3-2c78c2303f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ed431-b477-4391-a017-b8ccedd73225",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, Squeezing and Unsqueezing Tensors\n",
    "1. Reshaping - reshapes an input tensor to the desired shape\n",
    "2. View - Returns a view of the input tensor shape but keeps the same memory as the original tensor\n",
    "3. Stacking - Combines multiple tensors side by side (hastack), Colbines multiple tensors on top of each other(vstack)\n",
    "4. Squeeze - removes all '1' dimension from the tensor\n",
    "5. Unsqueeze - adds '1' dimension to the vector\n",
    "6. Permute - Returns a view of the input with dimensions swapped in the desired way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "003294d2-0214-4250-ae0b-6004fd905500",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.arange(1.5,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "11356570-38c3-4c87-ae02-3299746d348d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.5000,  2.5000,  3.5000,  4.5000,  5.5000,  6.5000,  7.5000,  8.5000,\n",
       "          9.5000, 10.5000]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2c020832-6c38-4ff6-bbc3-c621fd6d50db",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 6]' is invalid for input of size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reshape - \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# adds an extra dimension to the tensor\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m y_reshaped \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 6]' is invalid for input of size 7"
     ]
    }
   ],
   "source": [
    "# Reshape - \n",
    "# adds an extra dimension to the tensor\n",
    "y_reshaped = y.reshape(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9bfa8f05-b01d-40d4-b8e4-340d84476781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.5000,  2.5000,  3.5000,  4.5000,  5.5000],\n",
       "         [ 6.5000,  7.5000,  8.5000,  9.5000, 10.5000]]),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped = y.reshape(2,5)\n",
    "y_reshaped, y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5b68f6fa-668a-4b3b-9203-e27280603b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.5000,  2.5000],\n",
       "         [ 3.5000,  4.5000],\n",
       "         [ 5.5000,  6.5000],\n",
       "         [ 7.5000,  8.5000],\n",
       "         [ 9.5000, 10.5000]]),\n",
       " torch.Size([5, 2]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped = y.reshape(5,2)\n",
    "y_reshaped, y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ec7b2a9f-407e-45e1-aefc-67adc565c6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.5000,  2.5000,  3.5000,  4.5000,  5.5000,  6.5000,  7.5000,  8.5000,\n",
       "           9.5000, 10.5000]]),\n",
       " torch.Size([1, 10]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the view\n",
    "z = y.view(1,10)\n",
    "z, z.shape, y.shape\n",
    "# changing z, changes y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0ef428f8-dc91-478c-9b08-8b8a815608db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.5000,  2.5000,  3.5000, 55.9000,  5.5000,  6.5000,  7.5000,  8.5000,\n",
       "           9.5000, 10.5000]]),\n",
       " tensor([ 1.5000,  2.5000,  3.5000, 55.9000,  5.5000,  6.5000,  7.5000,  8.5000,\n",
       "          9.5000, 10.5000]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,3] = 55.9\n",
    "z, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "91a3af89-0da0-4b64-a627-268dd635bff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5000,  1.5000,  1.5000],\n",
       "        [ 2.5000,  2.5000,  2.5000],\n",
       "        [ 3.5000,  3.5000,  3.5000],\n",
       "        [55.9000, 55.9000, 55.9000],\n",
       "        [ 5.5000,  5.5000,  5.5000],\n",
       "        [ 6.5000,  6.5000,  6.5000],\n",
       "        [ 7.5000,  7.5000,  7.5000],\n",
       "        [ 8.5000,  8.5000,  8.5000],\n",
       "        [ 9.5000,  9.5000,  9.5000],\n",
       "        [10.5000, 10.5000, 10.5000]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stacking Tensors on top of each other\n",
    "y_stacked = torch.stack([y,y,y], dim = 1)\n",
    "y_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "65c2d56b-2065-4bd5-842f-edba954b7fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5000,  2.5000,  3.5000, 55.9000,  5.5000,  6.5000,  7.5000,  8.5000,\n",
       "          9.5000, 10.5000],\n",
       "        [ 1.5000,  2.5000,  3.5000, 55.9000,  5.5000,  6.5000,  7.5000,  8.5000,\n",
       "          9.5000, 10.5000]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_stacked = torch.stack([y,y], dim = 0)\n",
    "y_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce3918-4d2f-471a-9d5f-6a68a1cc7856",
   "metadata": {},
   "source": [
    "### torch.squeeze() -  Returns a tensor with all specified dimensions of input of size 1 removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "87eddb73-6d76-4e9f-9e8a-f84579030a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 1.9000, 2.8000, 3.7000, 4.6000, 5.5000, 6.4000, 7.3000, 8.2000]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1,9,0.9)\n",
    "y,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8e1dd731-0cbe-427b-8026-740b6d5a2261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.9000, 2.8000, 3.7000, 4.6000, 5.5000, 6.4000, 7.3000, 8.2000]]),\n",
       " torch.Size([1, 9]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped = y.reshape(1,9)\n",
    "y_reshaped, y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a0abf13d-a9dc-46d7-a025-991a0e999e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 1.9000, 2.8000, 3.7000, 4.6000, 5.5000, 6.4000, 7.3000, 8.2000]),\n",
       " torch.Size([9]),\n",
       " torch.Size([1, 9]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.squeeze(), y_reshaped.squeeze().shape, y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3dffbacd-0ae3-424a-9a01-13b97275282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.9000, 2.8000, 3.7000, 4.6000, 5.5000, 6.4000, 7.3000, 8.2000]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6b775108-273c-498f-b9e2-0899ababa3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.0000, 1.9000, 2.8000, 3.7000, 4.6000, 5.5000, 6.4000, 7.3000,\n",
       "           8.2000]]]),\n",
       " torch.Size([1, 1, 9]))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped = y.reshape(1,1,9)\n",
    "y_reshaped, y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a332d7a4-ae7a-4aa6-bd41-0e0471ea7431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 1.9000, 2.8000, 3.7000, 4.6000, 5.5000, 6.4000, 7.3000, 8.2000]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped.squeeze(), y_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6a646540-37b0-4c49-b962-c8efda7bad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is tensor([[[1.0000, 1.9000, 2.8000, 3.7000, 4.6000, 5.5000, 6.4000, 7.3000,\n",
      "          8.2000]]])\n",
      "The shape of the originl tensor is torch.Size([1, 1, 9])\n",
      "\n",
      "\n",
      "\n",
      "The squeezed tensor is(it removes all the one dimensions from the vectors) - tensor([1.0000, 1.9000, 2.8000, 3.7000, 4.6000, 5.5000, 6.4000, 7.3000, 8.2000])\n",
      "\n",
      "The shape of the squeezed tensor of squeeze dimension is torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The original tensor is {y_reshaped}\")\n",
    "print(f\"The shape of the originl tensor is {y_reshaped.shape}\")\n",
    "print(\"\\n\")\n",
    "print(f\"\\nThe squeezed tensor is(it removes all the one dimensions from the vectors) - {y_reshaped.squeeze()}\")\n",
    "print(f\"\\nThe shape of the squeezed tensor of squeeze dimension is {y_reshaped.squeeze().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f80ce5-de11-4542-8918-d0f418b2d8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b982d3-c314-4a99-b51f-26e21050f1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f77192-897c-448f-a767-47cab6f6b64d",
   "metadata": {},
   "source": [
    "### torch.unsqueeze() -  adds a single dimension to the target tensor at a specific dimension\n",
    "Here specific dimension in the sense when we are getting the shape of the tensor, we have dimensions like - 0,1,2.              \n",
    "When we mention in the unsqueeze the dimension, the changes happens in that dimension specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ab36e351-c7ba-4c6d-be78-b7f954be99af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5,  7,  9, 11, 13, 15, 17, 19]), torch.Size([8]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.arange(5,20,2)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b634d807-129a-48c4-9289-4976844cbed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is tensor([ 5,  7,  9, 11, 13, 15, 17, 19])\n",
      "The shape of the originl tensor is torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The original tensor is {x}\")\n",
    "print(f\"The shape of the originl tensor is {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2cc67761-27f9-4005-bc03-e434d0c5283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is tensor([ 5,  7,  9, 11, 13, 15, 17, 19])\n",
      "The unsqueezed tensor is tensor([[ 5,  7,  9, 11, 13, 15, 17, 19]])\n",
      "The shape of the unsqueezed tensor is torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "# unsqueezing at the 0th dimension - \n",
    "print(f\"The original tensor is {x}\")\n",
    "print(f\"The unsqueezed tensor is {x.unsqueeze(dim = 0)}\")\n",
    "print(f\"The shape of the unsqueezed tensor is {x.unsqueeze(dim = 0).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "70979986-b60a-4beb-8adb-2f86e9389223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is tensor([ 5,  7,  9, 11, 13, 15, 17, 19])\n",
      "The unsqueezed tensor is\n",
      " tensor([[ 5],\n",
      "        [ 7],\n",
      "        [ 9],\n",
      "        [11],\n",
      "        [13],\n",
      "        [15],\n",
      "        [17],\n",
      "        [19]])\n",
      "The shape of the unsqueezed tensor is torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "# unsqueezing at the 1th dimension -  it will change into 8,1 matrix\n",
    "print(f\"The original tensor is {x}\")\n",
    "print(f\"The unsqueezed tensor is\\n {x.unsqueeze(dim = 1)}\")\n",
    "print(f\"The shape of the unsqueezed tensor is {x.unsqueeze(dim = 1).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7acef8cd-c7dc-479e-a26f-98d950a00aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is tensor([ 5,  7,  9, 11, 13, 15, 17, 19])\n",
      "The shape of the originl tensor is torch.Size([8])\n",
      "The unsqueezed tensor is\n",
      " tensor([[ 5],\n",
      "        [ 7],\n",
      "        [ 9],\n",
      "        [11],\n",
      "        [13],\n",
      "        [15],\n",
      "        [17],\n",
      "        [19]])\n",
      "The shape of the unsqueezed tensor is torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "# unsqueezing at the -1th dimension - \n",
    "print(f\"The original tensor is {x}\")\n",
    "print(f\"The shape of the originl tensor is {x.shape}\")\n",
    "print(f\"The unsqueezed tensor is\\n {x.unsqueeze(dim = -1)}\")\n",
    "print(f\"The shape of the unsqueezed tensor is {x.unsqueeze(dim = -1).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "95fe2860-835f-4f84-a394-7fc1b01d9913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is tensor([ 5,  7,  9, 11, 13, 15, 17, 19])\n",
      "The shape of the originl tensor is torch.Size([8])\n",
      "The unsqueezed tensor is\n",
      " tensor([[ 5,  7,  9, 11, 13, 15, 17, 19]])\n",
      "The shape of the unsqueezed tensor is torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "# unsqueezing at the -1th dimension - \n",
    "print(f\"The original tensor is {x}\")\n",
    "print(f\"The shape of the originl tensor is {x.shape}\")\n",
    "print(f\"The unsqueezed tensor is\\n {x.unsqueeze(dim = -2)}\")\n",
    "print(f\"The shape of the unsqueezed tensor is {x.unsqueeze(dim = -2).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7999f154-12d5-4217-8040-63af2506f823",
   "metadata": {},
   "source": [
    "## Torch Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7fba82fb-1778-4706-bbba-6d1975cb036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "53df1334-d3b5-40ab-b0bc-1a8aac91941d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5649, -0.6694,  0.2793,  0.1273,  1.6874],\n",
       "         [-0.4471, -0.4358, -0.6261,  2.0579,  0.6755],\n",
       "         [-0.4839, -0.5092, -0.8075, -0.3421, -1.0141]],\n",
       "\n",
       "        [[-1.5333, -1.8683, -0.8993, -0.1407, -0.7839],\n",
       "         [-1.0712,  0.4771, -0.6805, -0.1231,  0.1059],\n",
       "         [ 0.0283, -1.5163, -1.4571, -1.3441, -1.9353]]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e1afaa29-520a-4aa8-9602-6627ad5b1ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.5649, -1.5333],\n",
       "          [-0.4471, -1.0712],\n",
       "          [-0.4839,  0.0283]],\n",
       " \n",
       "         [[-0.6694, -1.8683],\n",
       "          [-0.4358,  0.4771],\n",
       "          [-0.5092, -1.5163]],\n",
       " \n",
       "         [[ 0.2793, -0.8993],\n",
       "          [-0.6261, -0.6805],\n",
       "          [-0.8075, -1.4571]],\n",
       " \n",
       "         [[ 0.1273, -0.1407],\n",
       "          [ 2.0579, -0.1231],\n",
       "          [-0.3421, -1.3441]],\n",
       " \n",
       "         [[ 1.6874, -0.7839],\n",
       "          [ 0.6755,  0.1059],\n",
       "          [-1.0141, -1.9353]]]),\n",
       " torch.Size([5, 3, 2]))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch. permute rearranges the dimension of the input with the given permutations\n",
    "x.permute(2,1,0), x.permute(2,1,0).shape\n",
    "#5,3,2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55e2a5-2d22-4b1b-97e9-7fe9f183f8aa",
   "metadata": {},
   "source": [
    "## Pytorch Tensors and Numpy\n",
    "Pytorch has functionality to interact with numpy.\n",
    "* Your Data in Numpy Array ----> Want in Pytorch Tensor - `torch.from_numpy(ndarray)`\n",
    "* Pytorch Tensor ----> Numpy Array - `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8ddf678b-99fd-4469-a5ba-7efa48233207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  4,  7, 10, 13, 16, 19]), array([ 1,  3,  5,  7,  9, 11, 13]))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to tensor\n",
    "import numpy as np\n",
    "\n",
    "array_1 = np.arange(1,15,2)\n",
    "array_1\n",
    "tensor_1 = torch.arange(1,20,3)\n",
    "tensor_1, array_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dd2989b7-42b6-44cb-8e55-03458bc113de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  3,  5,  7,  9, 11, 13]), torch.int64)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch = torch.from_numpy(array_1)\n",
    "new_torch, new_torch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2af23ce1-d4a4-490f-9618-661592657843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when converting from numpy to tensor, pytorch will keep the numpys original datatype of float64 unless\n",
    "# specially mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a20fe8a7-46c3-42fd-a686-7b11e3d2848a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  3.,  5.,  7.,  9., 11., 13.]), torch.float32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_torch = torch.from_numpy(array_1).type(torch.float32)\n",
    "new_torch, new_torch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "db119252-7ff5-48ba-8c79-5a41c8a54e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  4,  7, 10, 13, 16, 19]), dtype('int64'))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "new_array = tensor_1.numpy()\n",
    "new_array, new_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb503b67-091d-43ed-93a5-b65c0f4e79a2",
   "metadata": {},
   "source": [
    "## Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f0b510fe-7657-491e-a5da-300966e6ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cude\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553afd3-63c4-413a-b7e1-e8fa2e71ffea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811126aa-552f-4123-9810-a7841e799d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe90f76-c117-4ccb-87b6-7870f2b9ed47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3323f29-49ca-4af2-970e-a3f1e201cbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7f39a-6868-49ca-9e03-d1c6f5e86778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd02ec26-2ccd-45b7-8d9a-21cdd1a1a070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d263f9-9c79-4e35-adea-df8ab60cf5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979613f3-05a7-4f08-a811-61e4133a78bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf33153-e26a-48f9-ba46-7923918c018c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d3b36-014f-4dc9-b6c2-d7483e6a6873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
